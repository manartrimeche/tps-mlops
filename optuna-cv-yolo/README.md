# TP6 : Optimisation des Hyperparam√®tres avec Optuna (YOLO tiny)

Ce projet correspond au TP6 du cours MLOps et a pour objectif d‚Äôindustrialiser l‚Äôoptimisation des hyperparam√®tres d‚Äôun mod√®le de vision par ordinateur (YOLOv8 tiny). Il s‚Äôappuie sur **Optuna** pour la recherche des meilleurs param√®tres et **MLflow** pour le suivi des exp√©riences.

---

## üèóÔ∏è Architecture Technique

- **Mod√®le** : YOLOv8 tiny (ultralytics)
- **Jeu de donn√©es** : Tiny COCO (personnes uniquement), g√©r√© avec **DVC**
- **Suivi des exp√©riences** : **MLflow** (param√®tres, m√©triques, artefacts)
- **Stockage des artefacts** : **MinIO** (compatible AWS S3)
- **Optimisation** : **Optuna** (TPE)
- **Infrastructure** : Docker Compose

---

## üöÄ Installation et D√©marrage

### 1. Pr√©requis

- Docker & Docker Compose
- Python 3.8 ou sup√©rieur
- Git

### 2. Lancement des services

D√©marrez la stack MLflow et MinIO :

```bash
docker compose up -d
```

- **MLflow UI** : http://localhost:5000
- **MinIO Console** : http://localhost:9001 (Utilisateur : `minio`, Mot de passe : `minio12345`)

### 3. Pr√©paration de l‚Äôenvironnement Python

```bash
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

### 4. Configuration des variables d‚Äôenvironnement

Pour permettre au script Python de communiquer avec MinIO et MLflow :

```powershell
$env:MLFLOW_TRACKING_URI = "http://localhost:5000"
$env:MLFLOW_S3_ENDPOINT_URL = "http://localhost:9000"
$env:AWS_ACCESS_KEY_ID = "minio"
$env:AWS_SECRET_ACCESS_KEY = "minio12345"
```

---

## üèÉ‚Äç‚ôÇÔ∏è Ex√©cution des Exp√©riences

### 1. Ex√©cution du baseline

Lancez un entra√Ænement simple pour valider la pipeline :

```bash
python -m src.train_cv --epochs 3 --imgsz 320 --exp-name yolo_baseline
```

### 2. Recherche par grille (Grid Search)

Lancez une recherche na√Øve sur une grille pr√©d√©finie d‚Äôhyperparam√®tres :

```powershell
.\scripts\run_grid.ps1
```

### 3. Optimisation avanc√©e avec Optuna

Lancez l‚Äôoptimisation bay√©sienne des hyperparam√®tres :

```powershell
.\scripts\run_optuna.ps1 --n-trials 5
```

---

## üìä Rapport de D√©cision

### 1. Contexte

- **Objectif** : Maximiser la pr√©cision de d√©tection des personnes sur Tiny COCO
- **Mod√®le** : YOLOv8n (Nano), choisi pour sa rapidit√©
- **M√©trique cible** : `metrics/mAP50(B)` (Mean Average Precision √† IoU 0.5)

![Baseline Run](img/baseline-optuna.png)
_Fig 1. Run baseline initial dans MLflow_

### 2. R√©sum√© des exp√©riences Optuna

Une √©tude de 5 essais a permis d‚Äôoptimiser deux hyperparam√®tres principaux : `epochs` (2 √† 5) et `imgsz` (320 √† 416).

| Trial ID    | Epochs | Imgsz   | mAP50 (Score) | Statut      |
| ----------- | ------ | ------- | ------------- | ----------- |
| Trial 0     | 2      | 320     | 0.150         | ‚úÖ          |
| Trial 1     | 3      | 320     | 0.146         | ‚úÖ          |
| Trial 2     | 4      | 320     | 0.155         | ‚úÖ          |
| Trial 3     | 3      | 416     | 0.151         | ‚úÖ          |
| **Trial 4** | **5**  | **320** | **0.168**     | **üèÜ Best** |

### 3. Analyse et comparaison

#### Grid Search classique

![Grid Search Results](img/compare-without-optuna.png)
_Fig 2. R√©sultats des runs Grid Search classique. Les performances sont variables et la convergence n‚Äôest pas garantie._

#### Optuna vs Grid Search

- **Effet des epochs** : Augmenter le nombre d‚Äôepochs am√©liore nettement la performance (de 0.150 √† 0.168). Le mod√®le continue de progresser √† 5 epochs.
- **Effet de la taille d‚Äôimage (imgsz)** : Passer de 320 √† 416 n‚Äôapporte pas de gain significatif pour peu d‚Äôepochs, mais augmente le temps de calcul.
- **Optuna vs Grid Search** : Optuna converge rapidement vers les meilleurs param√®tres sans tester toutes les combinaisons inefficaces.

![Comparison With Optuna](img/compare-with_optuna.png)
_Fig 3. Comparaison incluant les runs Optuna, illustrant l‚Äôexploration efficace des hyperparam√®tres._

### 4. Recommandation pour le staging

Nous recommandons d‚Äôutiliser les hyperparam√®tres du **Trial 4** pour l‚Äôenvironnement de staging :

- **Configuration retenue** :
  - `epochs`: **5** (ou plus si le temps le permet)
  - `imgsz`: **320** (plus rapide que 416)
- **Performance attendue** : mAP50 ‚âà **0.168**

### 5. Discussion : Apport d‚ÄôOptuna en MLOps

L‚Äôint√©gration d‚ÄôOptuna dans la pipeline MLOps offre plusieurs avantages :

1. **Efficacit√©** : Optuna (TPE) cible les zones prometteuses, √©conomisant du temps et des ressources GPU.
2. **Automatisation** : L‚Äôoptimisation est automatis√©e, permettant de lancer des √©tudes sans supervision continue.
3. **Tracking unifi√©** : Gr√¢ce √† MLflow, chaque essai est trac√© et reproductible, assurant la tra√ßabilit√© du cycle de vie du mod√®le.

---

# optuna-cv-yolo

Optimisation d'hyperparam√®tres YOLOv8 avec Optuna.

- DVC pour la gestion des donn√©es
- MLflow pour le suivi des runs
- Scripts d'entra√Ænement et pipelines ZenML

## Acc√®s

Ouvrir le dossier `optuna-cv-yolo`.

## D√©marrage rapide

Voir le fichier `README.md` du dossier pour les instructions d√©taill√©es.
